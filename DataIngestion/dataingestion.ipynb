{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7639af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x2423a16e0e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "textloader=TextLoader(\"speech.txt\")\n",
    "textloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbc6625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content=\"Bernard of Sédirac (c. 1050 – 1125), also known as Bernard of Le Sauvetat, was the metropolitan archbishop of Toledo from 1086 and first primate of Spain from 1088 to his death. His significance in the history of Spain lies in the fact that during his episcopate the church of Castile and León emerges from its isolation. He is often confused with Bernard of Agen, first bishop of Sigüenza, who was also a Gascon and Cluniac monk.\\n\\nHe was born in Gascony around 1050, at La Sauvetat de Blanquefort (Lot-et-Garonne), near the town of Agen. It is thought he belonged to the ancient family of the viscounts of Sédirac (also spelled Sédilhac), whose castle, southwest of La Sauvetat, still stands. An illness forced Bernard to turn away from a military career and instead enter the monastic life.[1]\\n\\nHe became a monk in the Abbey of Cluny, whence he was sent to Spain with others to assist the cause of the reforms of Gregory VII. Here he was made (1080) abbot of St. Facundus at Sahagún in the diocese of León, and finally named for the archbishopric of Toledo by Alfonso VI of Castile, the great patron of Cluny.\\n\\nGregory's plans for Spain included (besides a general crusade against clerical marriage, simony, and lay investiture) the substitution of the Roman liturgy for the Mozarabic and pressure for recognition of obligations of tribute from the Spanish church. The former point had been practically gained before his death, in spite of strenuous opposition. Urban II, by raising Bernard's see to primatial dignity, gave him the power necessary to prosecute the work of Romanizing. His cooperation made possible Urban's intervention at the Synod of León (1091) and ignoring of the royal right of investiture when Alfonso attempted to appoint a Castilian to the see of Santiago de Compostela, apparently in order to counterbalance the influence of the Cluniac Benedictines with whom the archbishop was filling the episcopal sees.\\n\\nHis career was throughout that of a devoted adherent of the papacy. Some reminiscences of his youthful days as a knight appear in his forcible seizure of the mosque at Toledo in his first year as archbishop and in his plans for a crusade against the Saracens of the East, which both Urban II and Paschal II forbade in view of the tasks which Spanish Christian knighthood faced at home.\\n\\nFour of his sermons, on the Salve Regina, are included among those of the great Bernard of Clairvaux. He was satirized in the 11th-century work, The Treatise of Garcia of Toledo, said to have been written by one of his canons.\")]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documnet=textloader.load()\n",
    "text_documnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a363728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader# for the load the pdf formats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa82793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web base loader \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "webbase_loader=WebBaseLoader(web_paths=(\"https://simonwillison.net/2025/Sep/18/agents/\",),bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-title\",\"post-content\",\"post-header\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde0c51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://simonwillison.net/2025/Sep/18/agents/'}, page_content='')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbase_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ac503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs=ArxivLoader(query=\"1706.03762\",load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25094bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdc23a",
   "metadata": {},
   "source": [
    "# Data Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "149ef66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=11\n",
    "                                             )\n",
    "final_docs=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13c99716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n",
      "page_content='Google hereby grants permission to' metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}\n"
     ]
    }
   ],
   "source": [
    "print(final_docs[0])\n",
    "print(final_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32960e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rating",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
